= 外部認証プロバイダ(LDAP)の設定

== 演習の概要
OpenShiftは多くの異なる認証プロバイダをサポートしています。完全なリストは link:https://docs.openshift.com/container-platform/4.5/authentication/understanding-identity-provider.html[understanding
identity provider configuration] に記載されています。最も一般的に使用されている認証プロバイダの1つはLDAPです。Microsoft Active Directoryによって提供されているか、他のソースから提供されているかにはよりません。

OpenShiftはLDAPサーバーに対してユーザ認証を実行することができます。LDAPのグループメンバーシップに基づいて、グループメンバーシップと特定のRBAC属性を設定することもできます。

---

### 前提知識: LDAPの構造

この環境では、以下のユーザグループでLDAPを提供しています。

* `ose-user`: OpenShiftにアクセスできるユーザ
** OpenShiftにログインできるユーザは、このグループのメンバーでなければなりません。
** 以下のユーザはすべてこのグループに属しています。
* `ose-normal-dev`: 通常のOpenShiftユーザ
** 特別な権限を持たない正規のOpenShiftユーザ
** 例: `normaluser1`, `teamuser1`, `teamuser2`
* `ose-fancy-dev`: 特殊なOpenShiftユーザ
** いくつかの特別な権限が付与されているOpenShiftのユーザ
** 例: `fancyuser1`, `fancyuser2`
* `ose-teamed-app`: チームに属するアプリケーションユーザ
** 同じOpenShift *Project* にアクセスできるユーザのグループ
** 例: `teamuser1`, `teamuser2`

#### OAuth の設定を調べる
この環境は何も手を加えていない「バニラ」なOpenShift 4のインストールなので、デフォルトのOAuthリソースを持っています。そのOAuth設定を以下で調べることができます。

[source,bash,role="execute"]
----
oc get oauth cluster -o yaml
----

以下のように表示されます。

[source,yaml]
----
apiVersion: config.openshift.io/v1
kind: OAuth
metadata:
  annotations:
    include.release.openshift.io/ibm-cloud-managed: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
    release.openshift.io/create-only: "true"
  creationTimestamp: "2022-02-09T23:06:59Z"
  generation: 1
  name: cluster
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    kind: ClusterVersion
    name: version
    uid: c9cbd13c-99bf-4e82-b2ad-690810a01f2f
  resourceVersion: "1715"
  uid: 1bedd82d-b235-4e39-af98-e40f411c3c8e
spec: {}
----

ここで注意すべきことがいくつかあります。まず、ここには基本的に何もありません!では、`kubeadmin` ユーザはどのように動作するのでしょうか?OpenShift OAuthシステムは、`kube-system` *Namespace* にある`kubeadmin` *Secret* を探すことができます。次のように調べることができます。

[source,bash,role="execute"]
----
oc get secret -n kube-system kubeadmin -o yaml
----

以下のように表示されます。

[source,yaml]
----
apiVersion: v1
data:
  kubeadmin: JDJhJDEwJFYwcVBXRjZGTlNOOU1RYUN6SGtJVGV4T3I5Ym9DbGRTT0VmNS44UGl2cWZOUGdsTnkvb3hT
kind: Secret
metadata:
  creationTimestamp: "2022-02-09T23:06:14Z"
  name: kubeadmin
  namespace: kube-system
  resourceVersion: "576"
  uid: 834a86fd-96e6-4d6a-8c16-6eca251b10f0
type: Opaque
----

この `Secret` には、`kubeadmin` パスワードがエンコードされたハッシュが含まれています。このアカウントは、新しい `OAuth` を設定した後も動作します。このアカウントを無効にしたい場合は、Secretを削除する必要があります。

実際の環境では、既存のID管理ソリューションと統合することをお勧めします。このラボでは、`identityProvider` としてLDAPを構成しています。以下はOAuth構成の例です。`identityProviders` で `type.LDAP` の要素に注目してみましょう。

[source,yaml]
----
apiVersion: config.openshift.io/v1
kind: OAuth
metadata:
  name: cluster
spec:
  identityProviders:
  - name: ldap <1>
    challenge: false
    login: true
    mappingMethod: claim <2>
    type: LDAP
    ldap:
      attributes: <3>
        id:
        - dn
        email:
        - mail
        name:
        - cn
        preferredUsername:
        - uid
      bindDN: "uid=openshiftworkshop,ou=Users,o=5e615ba46b812e7da02e93b5,dc=jumpcloud,dc=com" <4>
      bindPassword: <5>
        name: ldap-secret
      ca: <6>
        name: ca-config-map
      insecure: false
      url: "ldaps://ldap.jumpcloud.com/ou=Users,o=5e615ba46b812e7da02e93b5,dc=jumpcloud,dc=com?uid?sub?(memberOf=cn=ose-user,ou=Users,o=5e615ba46b812e7da02e93b5,dc=jumpcloud,dc=com)" <7>
  tokenConfig:
    accessTokenMaxAgeSeconds: 86400
----

`identityProviders:` 下にあるいくつかの注目すべきフィールド

<1> `name`: プロバイダの一意のID。OpenShift環境では複数の認証プロバイダを持つことが可能で、OpenShiftはそれらを区別することができます。

<2> `mappingMethod: claim`: このセクションは、複数のプロバイダが構成されている場合に、OpenShiftクラスタ内でユーザ名がどのように割り当てられるかに関係しています。詳細については、link:https://docs.openshift.com/container-platform/4.5/authentication/understanding-identity-provider.html#identity-provider-parameters-understanding-identity-provider[Identity provider parameters] のセクションを参照してください。

<3> `attributes`: このセクションでは、OpenShiftユーザの「アカウント」のフィールドに反復して割り当てるLDAPフィールドを定義します。リストを検索する際に属性が見つからない場合や、属性が入力されていない場合は認証全体が失敗します。上の例の場合は、LDAP `dn` からidを、LDAP `mail` からemailアドレスを、LDAP `cn` からの名前を、LDAP `uid` からユーザ名を、それぞれ関連付けます。

<4> `bindDN`: LDAPを検索する際に、このユーザとしてサーバーにバインドします。

<5> `bindPassword`: 検索時にバインドする際に使用するパスワードを持つSecretを参照します。

<6> `ca`: LDAPサーバーのSSL証明書を検証するために使用するCA証明書を含むConfigMapを参照します。

<7> `url`: LDAPサーバーのURLです。

OpenShiftにおけるLDAP認証の具体的な詳細については、link:https://docs.openshift.com/container-platform/4.10/authentication/identity_providers/configuring-ldap-identity-provider.html[Configuring
an LDAP identity provider]のドキュメントを参照してください。

LDAP IDプロバイダを設定するには、以下を行う必要があります。

1. バインドパスワードを使用して `Secret` を作成します。
2. CA 証明書を使用して `ConfigMap` を作成します。
3. `cluster` `OAuth` オブジェクトを LDAP IDプロバイダで更新します。

`kubeadmin` ユーザとして `oc` で OAuth 設定を適用します。

[source,bash,role="execute"]
----
oc login -u kubeadmin -p {{ KUBEADMIN_PASSWORD }}
----

次のコマンドは、openshift-config ネームスペースに ldap-secret という名前の Kubernetes Secretを、1つのデータアイテムで作成します。データアイテムは "bindPassword" という名前で、その値は "b1ndP^ssword" に設定されています。

[source,bash,role="execute"]
----
oc create secret generic ldap-secret --from-literal=bindPassword=b1ndP^ssword -n openshift-config
----

次のコマンドで、証明書をダウンロードし 'ca.crt' というファイルに保存します。

[source,bash,role="execute"]
----
wget https://certs.godaddy.com/repository/gd-class2-root.crt -O {{ HOME_PATH }}/support/ca.crt
----

----
もし、`Unable to establish SSL connection.` と表示された場合は、上記のコマンドを再度クリックしてから先に進んでください。
----

次のコマンドをクリックすると、openshift-config ネームスペースに ca-config-map という名前の新しい ConfigMap が作成されます。このConfigMapには、{{ HOME_PATH }}/support/ca.cltというファイルの内容が入力されます。そして、そのファイルを適用します。

[source,bash,role="execute"]
----
oc create configmap ca-config-map --from-file={{ HOME_PATH }}/support/ca.crt -n openshift-config
oc apply -f {{ HOME_PATH }}/support/oauth-cluster.yaml
----

[Note]
====
`apply` を使うのは既存の `OAuth` オブジェクトがあるためです。もし `create` を使用した場合、オブジェクトが既に存在しているというエラーが発生するでしょう。`apply` でも警告が表示されますが、それは問題ありません。
====

これにより、oAuth Operatorの再デプロイが開始されます。次のコマンドでロールアウトを監視することができます。

[source,bash,role="execute"]
----
oc rollout status deployment/oauth-openshift -n openshift-authentication
----

#### LDAPグループをOpenShiftグループに同期する
OpenShiftでは、グループを使用してユーザを管理し、複数のユーザの権限を一度に制御することができます。LDAPでグループを同期する方法については、link:https://docs.openshift.com/container-platform/4.10/authentication/ldap-syncing.html[Syncing LDAP groups
]の中にセクションがあります。グループを同期するには、`cluster-admin` 権限を持つユーザとしてOpenShiftにログインした状態で `groupsync` というプログラムを実行し、OpenShiftが様々なグループ内で見つけたユーザをどうするかを指示する設定ファイルを使う必要があります。

このラボでは次のような `groupsync` の設定ファイルを提供しています。

[source,bash,role="execute"]
----
cat {{ HOME_PATH }}/support/groupsync.yaml
----

あまり詳細には触れませんが (ドキュメントを見ることができます)、`groupsync` 設定ファイルは以下のようなことをします。

* 指定されたバインドユーザとパスワードを使って LDAPを検索する。
* 名前が `ose-` で始まるLDAPグループに対してクエリを実行する。
* LDAPグループの `cn` からとった名前を持つOpenShiftグループを作成する。
* LDAPグループのメンバーを見つけ、作成されたOpenShiftグループに入れる。
* OpenShiftでは `dn` と `uid` をそれぞれUIDとname属性として使用します。

`groupsync` を実行します。

[source,bash,role="execute"]
----
oc adm groups sync --sync-config={{ HOME_PATH }}/support/groupsync.yaml --confirm
----

以下のような出力になります。

----
group/ose-fancy-dev
group/ose-user
group/ose-normal-dev
group/ose-teamed-app
----

今見ているのは、`groupsync` コマンドで作成された *Group* オブジェクトです。もし `--confirm` フラグが気になる場合は、`oc adm groups sync -h` でヘルプの出力を確認してください。

作成された *Groups* を見たい場合は、以下を実行して下さい。

[source,bash,role="execute"]
----
oc get groups
----

以下のような出力が表示されます。

----
NAME             USERS
ose-fancy-dev    fancyuser1, fancyuser2
ose-normal-dev   normaluser1, teamuser1, teamuser2
ose-teamed-app   teamuser1, teamuser2
ose-user         fancyuser1, fancyuser2, normaluser1, teamuser1, teamuser2
----

YAMLで特定のグループを見てみましょう。

[source,bash,role="execute"]
----
oc get group ose-fancy-dev -o yaml
----

YAMLは以下のようになっています。

[source,yaml]
----
aapiVersion: user.openshift.io/v1
kind: Group
metadata:
  annotations:
    openshift.io/ldap.sync-time: "2022-02-10T01:49:07Z"
    openshift.io/ldap.uid: cn=ose-fancy-dev,ou=Users,o=5e615ba46b812e7da02e93b5,dc=jumpcloud,dc=com
    openshift.io/ldap.url: ldap.jumpcloud.com:636
  creationTimestamp: "2022-02-10T01:49:07Z"
  labels:
    openshift.io/ldap.host: ldap.jumpcloud.com
  name: ose-fancy-dev
  resourceVersion: "68628"
  uid: 374c463a-bdd2-4da1-ae1a-619eca0994f6
users:
- fancyuser1
- fancyuser2
----

OpenShiftは自動的にいくつかのLDAPメタデータを *Group* に関連付け、グループに含まれるユーザーを一覧表示します。

*Users* をリストアップするとどうなるでしょうか?

[source,bash,role="execute"]
----
oc get user
----

以下のように出てきます。

----
No resources found.
----

*Users* は *Group* の定義に明確にリストされているのに、なぜ *Users* が見つからないのでしょうか? 

*Users* は、最初にログインしようとするまで実際には作成されません。*Group* の定義に表示されているのは、OpenShiftがその特定のIDを持つ *User* に遭遇した場合、その *User* を *Group* に関連付けるべきであるとOpenShiftに伝えているだけのプレースホルダーです。

#### グループポリシーの変更
この環境では、`ose-fancy-dev` というスーパー開発者グループがあります。この人たちに特別な  `cluster-reader` 権限を与えてみましょう。これは、クラスタに関する管理レベルの情報を閲覧できるようにする役割です。たとえば、クラスター内のすべての *Projects* のリストを見ることができます。

`ose-fancy-dev` *Group* のポリシーを変更します。

[source,bash,role="execute"]
----
oc adm policy add-cluster-role-to-group cluster-reader ose-fancy-dev
----

[Note]
====
OpenShiftに付属するさまざまなロールに興味がある方は、link:https://docs.openshift.com/container-platform/4.10/authentication/using-rbac.html[Role-Based Access Control (RBAC)^] のドキュメントを参照してください。
====

#### cluster-reader ポリシーを調べる
通常のユーザでログインしてみましょう。

[source,bash,role="execute"]
----
oc login -u normaluser1 -p Op#nSh1ft
----

*Projects* をリストしてみると、

[source,bash,role="execute"]
----
oc get projects
----

この通り何も見えません。

----
No resources found.
----

次に `ose-fancy-dev` のメンバーとしてログインします。

[source,bash,role="execute"]
----
oc login -u fancyuser1 -p Op#nSh1ft
----

同じ `oc get projects` を実行すると、クラスタ内のすべての *Projects* のリストが表示されます。

----
NAME                                                    DISPLAY NAME                        STATUS
    app-management
    default
    kube-public
    kube-system
    labguide
    openshift
    openshift-apiserver
...
----

これで、OpenShift Container PlatformのRBACがどのように機能するか理解し始めているはずです。

#### コラボレーションのためのProjectの作成
cluster-admin としてログインしてください。

[source,bash,role="execute"]
----
oc login -u kubeadmin -p {{ KUBEADMIN_PASSWORD }}
----

そして、複数の人で共同作業を行うためにいくつかの *Project* を作成してください。

[source,bash,role="execute"]
----
oc adm new-project app-dev --display-name="Application Development"
oc adm new-project app-test --display-name="Application Testing"
oc adm new-project app-prod --display-name="Application Production"
----

これで、典型的なソフトウェア開発ライフサイクルを表す複数の *Project* が作成されました。次に、これらのProjectへの共同アクセスを許可するための *Group* を構成します。


[Note]
====
`oc adm new-project` でProjectを作成しても、Project requestプロセスやProject requestテンプレートは使われません。これらのProjectには、デフォルトではクォータや制限範囲が適用されません。クラスタ管理者は他のユーザに「なりすます」ことで、これらのProjectにクォータや制限範囲を適用したい場合には、いくつかのオプションがあります。

. 通常のユーザになりすますことを指定するために `--as` を使用して `oc new-project` を指定します。
. `oc process` を使用して、Project requestテンプレートの値を指定し、createにパイプします(例: `oc process ... | oc create -f -)。これにより、Project requestテンプレート内のすべてのオブジェクトが作成され、その中にはクォータと制限範囲が含まれます。

これらの演習では、Projectにクォータや制限範囲を設定することは重要ではありません。
====

#### GroupsをProjectにマップする
先ほど見たように、OpenShift内にはいくつかのロールがあらかじめ設定されています。 *Project* に関しても同様に、閲覧(View)、編集(Edit)、管理者アクセスを付与することができます。`ose-teamed-app` のユーザにDevelopment ProjectとTest Projectを編集するためのアクセス権を与えてみましょう。

[source,bash,role="execute"]
----
oc adm policy add-role-to-group edit ose-teamed-app -n app-dev
oc adm policy add-role-to-group edit ose-teamed-app -n app-test
----

そして、Productionを閲覧するためのアクセス権を与えます。

[source,bash,role="execute"]
----
oc adm policy add-role-to-group view ose-teamed-app -n app-prod
----

次に、`ose-fancy-dev` グループにProduction Projectの編集アクセス権を与えます。

[source,bash,role="execute"]
----
oc adm policy add-role-to-group edit ose-fancy-dev -n app-prod
----

#### Examine Group Access
`normaluser1` としてログインし、どのような *Projects* が表示されるか確認します。

[source,bash,role="execute"]
----
oc login -u normaluser1 -p Op#nSh1ft
oc get projects
----

このようになるはずです。

----
No resources found.
----

次に `ose-teamed-app` グループの `teamuser1` で試してみます。

[source,bash,role="execute"]
----
oc login -u teamuser1 -p Op#nSh1ft
oc get projects
----

このようになるはずです。

----
NAME       DISPLAY NAME              STATUS
app-dev    Application Development   Active
app-prod   Application Production    Active
app-test   Application Testing       Active
----

チームユーザにはProduction Projectへの編集アクセス権が付与されていません。次に、Production Projectに `teamuser1` として何かを作成してみてください。

[source,bash,role="execute"]
----
oc project app-prod
oc new-app docker.io/siamaksade/mapit
----

以下のようにうまくいかないことが分かります。

----
error: can't lookup images: imagestreamimports.image.openshift.io is forbidden: User "teamuser1
" cannot create resource "imagestreamimports" in API group "image.openshift.io" in the namespac
e "app-prod"
error:  local file access failed with: stat docker.io/siamaksade/mapit: no such file or directo
ry
error: unable to locate any images in image streams, templates loaded in accessible projects, t
emplate files, local docker images with name "docker.io/siamaksade/mapit"

Argument 'docker.io/siamaksade/mapit' was classified as an image, image~source, or loaded templ
ate reference.

The 'oc new-app' command will match arguments to the following types:

  1. Images tagged into image streams in the current project or the 'openshift' project
     - if you don't specify a tag, we'll add ':latest'
  2. Images in the Docker Hub, on remote registries, or on the local Docker engine
  3. Templates in the current project or the 'openshift' project
  4. Git repository URLs or local paths that point to Git repositories

--allow-missing-images can be used to point to an image that does not exist yet.

See 'oc new-app -h' for examples.
----

このエラーは想定通りのものです。

#### Prometheus
`cluster-reader` 権限を持つユーザ (クラスタ管理の多くの情報を閲覧することができるユーザ) ができたので、Prometheusをもう一度見てみましょう。

`cluster-reader` 権限を持つユーザでログインします。

[source,bash,role="execute"]
----
oc login -u fancyuser1 -p Op#nSh1ft
----

`prometheus` の `Route` を検索します。

[source,bash,role="execute"]
----
oc get route prometheus-k8s -n openshift-monitoring -o jsonpath='{.spec.host}{"\n"}'
----

以下のように表示されます。

----
prometheus-k8s-openshift-monitoring.{{ ROUTE_SUBDOMAIN }}
----

[Warning]
====
先に進む前に、OpenShiftのWebコンソールに移動し、右上の`kube:admin` のドロップダウンメニューからログアウトしてください。そうしないと、Prometheusは認証を通過するためにあなたの `kubeadmin` ユーザを使用しようとします。もちろんこれは動作しますが、`cluster-reader` ロールのデモンストレーションにはなりません。
====
インストーラは、デフォルトでPrometheus用の`Route`を設定しています。
link:https://prometheus-k8s-openshift-monitoring.{{ ROUTE_SUBDOMAIN }}[Prometheus Link]
をcontrol+クリックしてブラウザで開きます。ログイン画面が出てきたら *Log in with OpenShift* ボタンをクリックして `ldap` auth を選択し、先ほど `cluster-reader` 権限を付与した `fancyuser1` ユーザを使用します。

より細かく言えば、`ose-fancy-dev` グループに `cluster-reader` 権限があり、`fancyuser1` がメンバーです。これらのユーザのパスワードはすべて `Op#nSh1ft` です。自己署名証明書のため、証明書エラーが出ると思います。必ず承諾するようにしましょう。

ログインすると、最初にauthプロキシのパーミッションの承認画面が表示されます。

.Auth Proxy Acceptance.
image::images/prometheus-auth-proxy.png[]

実際には、あなたとPrometheusコンテナの間のフローの中にOAuthプロキシが存在します。このプロキシは、あなたの認証(AuthenticatioN:AuthN)を確認するためと、また、何が許可されているかの認可(AuthoriZe:AuthZ)のためにに使用されます。ここでは、Prometheusへのアクセスの一部として使用される `fancyuser1` アカウントのパーミッションを明示的に承認しています。_Allow selected permissions_ をクリックします。

この時点でPrometheusが表示されています。アラートは設定されていません。`Status` と `Targets` を見ると、クラスタの現在の状態に関する興味深い情報を見ることができます。

これが終わったら、管理者ユーザーとして再度ログインしてください。

[source,bash,role="execute"]
----
oc login -u kubeadmin -p {{ KUBEADMIN_PASSWORD }}
----
