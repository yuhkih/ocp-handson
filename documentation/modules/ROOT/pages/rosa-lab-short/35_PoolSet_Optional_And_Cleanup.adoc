:labname: Pool, Set, Optional task, and Clean up environment

include::../../include/00_0_Lab_Header.adoc[]

== {labname}

:numbered:
== Claim Cluster from Cluster Pool
プール内のクラスターがプロビジョニングされると、クラスター プールからクラスターを要求するプロセスは短時間で完了します (通常は約 1 分)。

.手順
. *Infrastructure -> Clusters* に移動します。
. *Cluster pools* タブを選択します。
. `production-uk` クラスター プール内の少なくとも 1 つのクラスターの *Status* が `Hibernating` になり、*Available to claim* が `yes` に変わるまで待ちます。
+
image::images/deployed-cluster-pool.png[width=80%]

.  `production-uk` クラスタ プールの `Claim cluster` をクリックします。
. *Cluster claim name* を `uk-1` に設定します。
. *Claim* をクリックします。
. 確認ダイアログ ボックスで、*View cluster* をクリックします。
. クラスターの  *Overview* ページで、クラスターが再開されていることを確認します。 数分以内に、要求されたクラスターを使用できるようになります。
. クラスターが再開するのを待っている間に、*Infrastructure -> Clusters* に戻り、 *Cluster pools* タブを選択します。
.  `production-uk` クラスター プールに、要求したクラスターの代わりに新たなクラスターが表示されていることを確認します。 クラスター プールは常に、構成したサイズのままです。
. 一部のリソースを節約するには、`production-uk` クラスタ プールをスケールして `1` レプリカに戻します。
.. image:images/options_menu_icon.png[] (*Options*) をクリックし、*Scale cluster pool* を選択します。
.. *Desired cluster pool size* を `1` に設定します。
.. *Scale* をクリックします。

=== Use Cluster Pool Release Images

クラスター プール内のすべてのクラスターは、同じリリース イメージで作成されます。 新しいイメージが利用可能になったら、新しいリリース イメージを使用して新しいクラスターを作成することをお勧めします。

プール内の既存のクラスターは、この変更の影響を *受けない* ことに注意してください。

.手順
. *Cluster pools* タブで、`production-ireland` クラスター プールを見つけ、image:images/options_menu_icon.png[] (*Options*) をクリックし、*Update release images* を選択します。
. 他の使用可能なリリース イメージを選択します。 クラスター プールが OpenShift 4.9 の利用可能な最新リリースに既にある場合、利用可能なイメージは、他の主要な OpenShift リリース用である可能性があります。
+
image::images/pool_images.png[width=80%]

. 古いリリースを使用したくないので、*Cancel* をクリックしてダイアログ ボックスを終了します。

== Explore Cluster Sets

クラスター セットを使用して、ポリシー (環境、物理的な場所、サーバー ラック、部屋など) に基づいてクラスターを論理的にグループ化します。

クラスタ セットを使用すると、特定の環境でアクションを実行できます。 この演習では、すべてのクラスターが `production` クラスター セットに属しています。

また、クラスタをグループ化する機能を使用して、次のような機能をクラスタ セット レベルで有効にすることもできます。

* Submariner接続インターコネクト
* 役割ベースのアクセス制御 (RBAC)

クラスター セットを使用すると、クラスター セット全体に展開される分散アプリケーションを展開できます。 これにより、クラスター セットに沿ってアプリケーション オブジェクトを分散させ、セット全体を 1 つのクラスターとして扱い、Submariner を介してマルチクラスター ネットワーク機能を有効にすることができます。

.手順
. *Infrastructure -> Clusters* に移動します。
. *Cluster sets* タブを選択します。
+
image::images/cluster-sets.png[width=80%]

. `production` クラスター セットをクリックして、クラスター セットのプロパティを開きます。5 つのタブが表示されます。

* Overview
* Submariner add-ons
* Managed clusters
* Cluster pools
* Access management

. *Cluster pools* タブに切り替えます。
+
image::images/cs-cluster-pools.png[width=80%]

. 前の手順で作成した両方のクラスター プールが一覧表示されていることを確認します。 これは、クラスター プール内のクラスターが現在、`production` クラスター セットの一部であることを示しています。

=== Use Cluster Sets for Access Management (RBAC)

クラスター セットを使用すると、クラスター セットおよびすべてのマネージド クラスターとやり取りするためのさまざまなアクセス許可を構成できます。 この構成はハブ クラスター用であることに注意してください。ハブ クラスター上のどのユーザーとグループが、クラスター セットとその管理対象クラスターと対話できるかを定義します。

この演習では、クラスター セットのアクセス許可を `user1` ユーザーに付与します。 ただし、それを行う前に、このユーザーとして 1 回ログインする必要があります。そうしないと、`user` オブジェクトがクラスターに存在せず、そのユーザーに権限を付与できません。

.手順
. _hub_ クラスターのbastionホストで、プロビジョニング メールに記載されているパスワードを使用して `user1` としてログインします。
+
[source,sh]
----
oc login -u user1 -p <user password> $(oc whoami --show-server)
----
+
.Sample Output
----
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>
----

. `admin` として再度ログインします。
+
[source,sh]
----
oc login -u admin
----

. ユーザーが作成されたことを確認します。
+
[source,sh]
----
oc get users
----
+
.Sample Output
[source,texinfo]
----
NAME     UID                                    FULL NAME   IDENTITIES
admin    4f028861-8ff3-43c3-9d40-638a59290e6f               htpasswd_provider:admin
user1    abfccf6b-daf6-42f3-8ec7-246041689bc0               htpasswd_provider:user1
----

. *Cluster set admin* パーミッションを *user1* に付与します。
.. RHACM コンソールで、*Infrastructure -> Clusters -> Cluster sets -> production* に移動します。
.. *Access management* タブに切り替えます。
.. *Add user or group* をクリックします。
.. *Select user or group* : `user1`
.. *Select role*: `Cluster set admin`
.. *Add* をクリックします。
+
OpenShift の `user1` ユーザーは、RHACM コンソールにログインして、`production` クラスター セットとそのクラスター セット内のすべてのクラスターを管理できるようになりました。


== Change Deployed Application (Optional)

すでにデプロイされているアプリケーションを更新する必要がある場合はどうなりますか?
ターゲット クラスタに直接変更を加えると、システムが同期しなくなる (最悪の場合) か、変更が上書きされて、`Channel` リソースのデプロイ可能オブジェクトによって定義された元の値に戻ります。
適切な方法は、リポジトリに保存されているマニフェストを変更することです。
これらの変更を行ったら、コミットして Git リポジトリにプッシュします。
そこから、RHACM に引き継がせて、それらが確実にデプロイされるようにします。

この演習はオプションです。

. _hub_ クラスタのBastion上で、フォークされた GitHub リポジトリのローカル クローンで、データベースの永続的なボリューム要求 (PVC) を定義する新しいファイルを作成し、そのファイルを `$HOME/rhacm-labs/resources/etherpad/postgres_pvc.yaml` として保存します。
+
[source,yaml]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    template: postgresql-persistent-template
  name: postgresql
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
----

. 使用する PVC を定義しましたが、ここで PostgreSQL の `Deployment` マニフェストを更新する必要があります。
`$HOME/rhacm-labs/resources/etherpad/postgres_deployment.yaml` ファイルを編集して、既存の `postgresql-data` ボリュームを次の内容に置き換えます。
+
[TIP]
====
このセクションは、ファイルの最後にあります。
====
+
[source,yaml]
----
...
volumes:
- name: postgresql-data
  persistentVolumeClaim:
    claimName: postgresql
----
. ファイルを保存します。

. 両方の変更をコミットして、GitHub リポジトリにプッシュします。この時、Githubのアカウントと、認証用のパスワード(トークン)を入力する必要があります。
+
[source,sh]
----
 cd $HOME/rhacm-labs
 git add resources/etherpad/postgres_pvc.yaml resources/etherpad/postgres_deployment.yaml
 git commit -m 'update postgres pvc and deployment'
 git push origin master
----

. _managed_ クラスターの `bastion` VM で、Pod を確認します。
約 1 分後、`Deployment` リソースが更新され、プロビジョニングした PVC を使用して新しい Pod が開始されるため、`postgresql`  Pod は `Terminating` 状態に移行することに注意してください。
+
[source,sh]
----
 oc get pod,pvc -n etherpad
----
+
.Sample Output
[source,sh,options="nowrap"]
----
NAME                              READY   STATUS    RESTARTS   AGE
pod/etherpad-5ccc6bdc6d-xr8nw     1/1     Running   2          67m
pod/postgresql-6df558f94c-djbvp   1/1     Running   0          5m42s

NAME                               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/postgresql   Bound    pvc-f4ccd5b8-e9ce-4348-a32b-ad38192fc697   10Gi       RWO            standard       21m
----

. オプションで、RHACM コンソールで新しいリソースを監視できます。
* 新しい `PVC` リソースがトポロジ ビューに表示されることを期待してください。
`PVC` リソースと PostgreSQL `Deployment` リソースの両方のデプロイ可能ファイルが更新されます。

アプリケーションのデプロイと更新に GitOps アプローチを採用しました。
構成を Git リポジトリに保存することで、小さな変更をプッシュするだけで変更を加えることができました。

== Application Deployment Control(Optional)
4章で作成したクラスタ、アプリケーションを用いて、さまざまなデプロイを試してみましょう。ここでは、クラスタのを編集することで、デプロイがどのように変わってくるかを確認しましょう。すでにApplicationが存在している場合には、一旦削除して、クラスターのラベルと`PlacementRule` を編集して、Applicationのデプロイ先がどう変わってくるか観察してみましょう。

.実施例
.. 4章では、`PlacementRule` で `environment` ラベルを指定してデプロイしました。他のラベル(guidやregion)を指定してデプロイしてみましょう。
.. 複数のクラスタに同じラベルを定義して、`PlacementRule` でそれを指定した場合に、Applicationがどこにデプロイされるか観察してみましょう。

== Clean Up Environment

ホスティング コストを節約するには、このラボで作成したクラスター プールをクリーンアップする必要があります。

.手順
. *Infrastructure -> Clusters -> Cluster pools* に移動します。
. 2 つのクラスター プールの横にあるボックスをオンにします。
. *Actions* をクリックし、*Destroy cluster pools* を選択します。
. 確認ダイアログ ボックスに `confirm` と入力し、*Destroy* をクリックします。
+
これにより、以前に要求したクラスターがクラスタープールから削除されるわけではありません。 要求されたクラスターも削除します。

. *Infrastructure -> Clusters* に移動します。
. `my-imported-cluster` クラスターの右にある image:images/options_menu_icon.png[] (*オプション*) をクリックします。
. *Detach cluster* を選択します。
. 確認ダイアログ ボックスに `confirm` と入力し、*Detach* をクリックします。
. `my-openshift-cluster` `production-uk-xxxx` クラスターの横にあるチェックボックスをオンにします。
. *Actions* をクリックし、*Destroy clusters* を選択します。
. 確認ダイアログ ボックスに `confirm` と入力し、*Destroy* をクリックします。
+
[NOTE]
これは、複数のクラスターを管理する 1 つの方法です。 もう 1 つのオプションは、image:images/options_menu_icon.png[] (*オプション*) をクリックして、*Destroy cluster* を選択することです。
